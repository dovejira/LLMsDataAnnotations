# LLMsDataAnnotations

This is an AI project where we discussed the feasibility and accuracy of using different large-scale models for annotation.

## Project Overview

In this document, we discussed several methods for conducting data annotation and compared their accuracy. Most of the code is encapsulated in functions and can be used for direct path swapping and analysis.

## Course Context

This project is part of the AI in J&C course assignment from Dr. Bao. Relevant issues have received support from course stakeholders and the school.

## Features

- Comparison of different data annotation methods
- Analysis of accuracy across various large-scale models
- Modular code structure for easy path swapping and analysis

## Project Steps

The source code has been uploaded. The specific steps are as follows:

1. Clarify the data for analysis and classification standards, then create a coding scheme. Manually code and verify coding consistency.

2. Obtain API keys for large language models.

3. Convert the content into jsonl files suitable for GPT and Gemini annotation through format conversion.

4. Fine-tune the models. For OpenAI, you can either select training parameters directly on their official website for fine-tuning, or use code to perform fine-tuning with default settings.

5. Conduct model predictions and accuracy verification.

6. Select the best-performing model for prediction and analysis.

## Results Overview

ChatGPT generally performs better than Gemini. Further testing can be conducted to analyze different types of text.


## Team Contributions

- **dovejira**: Responsible for code writing and data collection.
- **Evan**: In charge of finding literature support and coding.
- **Sio** and **Zoinka**: Responsible for literature annotation.

## Acknowledgements

Special thanks to Dr. Bao and the course stakeholders for their support on this project.
